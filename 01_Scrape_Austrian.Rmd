---
title: "Austrian Proposals and Bills"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Packages

```{r}
pacman::p_load(tidyverse, furrr, rvest, ggthemes, lubridate, rio, haven)

plan(multiprocess)
```

# Getting Index pages for XX - XXV legislative period

```{r}
# Reading stable URLs
XXV <- "https://www.parlament.gv.at/PAKT/VHG/index.shtml?VV=&pageNumber=&ZUAS=ALLE&ALT=&feldRnr=5&FR=ALLE&R_MSFRASZU=MIN&LDAP_GRP(PM_ESM)=N&DR=&FBEZ=FP_001&view=&VHG=GESVOR&VHG2=ALLE&jsMode=&VHG3=ALLE&requestId=C536DCDD28&VHG4=ALLE&MISS=&listeId=100&ALTKN=&filterJq=&AUS=ALLE&SUCH=&DEB=&xdocumentUri=%2FPAKT%2FVHG%2Findex.shtml&R_MFRAS=MIN&GP=XXV&STEP=2905&INTRANET=N&LDAP_GRP(PM_HA)=N&ZUFR=ALLE&NAB=&SID=ALLE&ascDesc=DESC&NRBR=NR&ALTPN=&GBEZ=&AS=ALLE&MIN=ALLE&LISTE=&ZUSTIMM=ALLE&LH=ALLE&GESVOR=ALLE&ZEIT="

XXIV <- "https://www.parlament.gv.at/PAKT/VHG/index.shtml?VV=&pageNumber=&ZUAS=ALLE&ALT=&feldRnr=5&FR=ALLE&R_MSFRASZU=MIN&LDAP_GRP(PM_ESM)=N&DR=&FBEZ=FP_001&view=&VHG=GESVOR&VHG2=ALLE&jsMode=&VHG3=ALLE&requestId=C536DCDD28&VHG4=ALLE&MISS=&listeId=100&ALTKN=&filterJq=&AUS=ALLE&SUCH=&DEB=&xdocumentUri=%2FPAKT%2FVHG%2Findex.shtml&R_MFRAS=MIN&GP=XXIV&STEP=2905&INTRANET=N&LDAP_GRP(PM_HA)=N&ZUFR=ALLE&NAB=&SID=ALLE&ascDesc=DESC&NRBR=NR&ALTPN=&GBEZ=&AS=ALLE&MIN=ALLE&LISTE=&ZUSTIMM=ALLE&LH=ALLE&GESVOR=ALLE&ZEIT="

XXIII <- "https://www.parlament.gv.at/PAKT/VHG/index.shtml?VV=&pageNumber=&ZUAS=ALLE&ALT=&feldRnr=5&FR=ALLE&R_MSFRASZU=MIN&LDAP_GRP(PM_ESM)=N&DR=&FBEZ=FP_001&view=&VHG=GESVOR&VHG2=ALLE&jsMode=&VHG3=ALLE&requestId=C536DCDD28&VHG4=ALLE&MISS=&listeId=100&ALTKN=&filterJq=&AUS=ALLE&SUCH=&DEB=&xdocumentUri=%2FPAKT%2FVHG%2Findex.shtml&R_MFRAS=MIN&GP=XXIII&STEP=2905&INTRANET=N&LDAP_GRP(PM_HA)=N&ZUFR=ALLE&NAB=&SID=ALLE&ascDesc=DESC&NRBR=NR&ALTPN=&GBEZ=&AS=ALLE&MIN=ALLE&LISTE=&ZUSTIMM=ALLE&LH=ALLE&GESVOR=ALLE&ZEIT="

XXII <-"https://www.parlament.gv.at/PAKT/VHG/index.shtml?VV=&pageNumber=&ZUAS=ALLE&ALT=&feldRnr=5&FR=ALLE&R_MSFRASZU=MIN&LDAP_GRP(PM_ESM)=N&DR=&FBEZ=FP_001&view=&VHG=GESVOR&VHG2=ALLE&jsMode=&VHG3=ALLE&requestId=C536DCDD28&VHG4=ALLE&MISS=&listeId=100&ALTKN=&filterJq=&AUS=ALLE&SUCH=&DEB=&xdocumentUri=%2FPAKT%2FVHG%2Findex.shtml&R_MFRAS=MIN&GP=XXII&STEP=2905&INTRANET=N&LDAP_GRP(PM_HA)=N&ZUFR=ALLE&NAB=&SID=ALLE&ascDesc=DESC&NRBR=NR&ALTPN=&GBEZ=&AS=ALLE&MIN=ALLE&LISTE=&ZUSTIMM=ALLE&LH=ALLE&GESVOR=ALLE&ZEIT="

XXI <- "https://www.parlament.gv.at/PAKT/VHG/index.shtml?VV=&pageNumber=&ZUAS=ALLE&ALT=&feldRnr=5&FR=ALLE&R_MSFRASZU=MIN&LDAP_GRP(PM_ESM)=N&DR=&FBEZ=FP_001&view=&VHG=GESVOR&VHG2=ALLE&jsMode=&VHG3=ALLE&requestId=C536DCDD28&VHG4=ALLE&MISS=&listeId=100&ALTKN=&filterJq=&AUS=ALLE&SUCH=&DEB=&xdocumentUri=%2FPAKT%2FVHG%2Findex.shtml&R_MFRAS=MIN&GP=XXI&STEP=2905&INTRANET=N&LDAP_GRP(PM_HA)=N&ZUFR=ALLE&NAB=&SID=ALLE&ascDesc=DESC&NRBR=NR&ALTPN=&GBEZ=&AS=ALLE&MIN=ALLE&LISTE=&ZUSTIMM=ALLE&LH=ALLE&GESVOR=ALLE&ZEIT="

XX <- "https://www.parlament.gv.at/PAKT/VHG/index.shtml?VV=&pageNumber=&ZUAS=ALLE&ALT=&feldRnr=5&FR=ALLE&R_MSFRASZU=MIN&LDAP_GRP(PM_ESM)=N&DR=&FBEZ=FP_001&view=&VHG=GESVOR&VHG2=ALLE&jsMode=&VHG3=ALLE&requestId=C536DCDD28&VHG4=ALLE&MISS=&listeId=100&ALTKN=&filterJq=&AUS=ALLE&SUCH=&DEB=&xdocumentUri=%2FPAKT%2FVHG%2Findex.shtml&R_MFRAS=MIN&GP=XX&STEP=2905&INTRANET=N&LDAP_GRP(PM_HA)=N&ZUFR=ALLE&NAB=&SID=ALLE&ascDesc=DESC&NRBR=NR&ALTPN=&GBEZ=&AS=ALLE&MIN=ALLE&LISTE=&ZUSTIMM=ALLE&LH=ALLE&GESVOR=ALLE&ZEIT="

index_urls <- c(XX, XXI, XXII, XXIII, XXIV, XXV)

```

# Scraping Metadata of indexpages and page URLs

```{r}
# get proposal pages URLs
scrape_indexpage <- function(url) { # URL = XXV, XXIV, XXIII, ...
  
  #read in page
  indexpage <- read_html(url)
  
  proposalpages <- indexpage %>%
    html_nodes("a.link-indicator") %>%
    html_attr("href") %>%
    .[seq(1, length(.), by = 2)] %>%
    paste0("https://www.parlament.gv.at", .)

  # get dates of proposals (website upload?), type (RV, A, VOLKBG, BRA), descriptive title, 
  indexpagedata <- indexpage %>%
    html_nodes(., "span.table-responsive__inner") %>%
    html_text(., trim = T) %>%  # get table inner text and trim
    matrix(., ncol = 5, byrow = T) %>%  # put into matrix, then dataframe (tibble)
    .[, -5] %>%
    as_tibble(., .name_repair = "minimal") %>%
    setNames(., c("web_date", "type", "desc_title", "proposal_id"))

  # add proposal pages URLs
  indexpagedata$proposal_link <- proposalpages
  
  # adding legislative period indicator
  indexpagedata$period <- url %>%
    str_extract(., "GP=\\w+") %>%
    str_sub(., start = 4)
  
  # add rudimentary status according to status bar (image)
  indexpagedata$status <- indexpage %>%
    html_nodes(., "img.status") %>%
    html_attr("src") %>%
    .[seq(1, length(.), by = 2)] %>%
    str_extract(., "[1-9]") %>%
    str_replace_all(.,c("5" = "beschlossen",
                        "4" = "nicht beschlossen",
                        "3" = "nicht beschlossen",
                        "2" = "nicht beschlossen",
                        "1" = "nicht beschlossen"))
    
    

  # cleaning proposal IDs to be used as filenames
  indexpagedata$proposal_filename <- indexpagedata$proposal_id %>%
    gsub("[^A-Za-z0-9]", "" , .) %>%
    paste(indexpagedata$period, ., sep = "_")
  
  #exporting to appropriatly named .csv
  write.csv(indexpagedata, file = paste0("data/df_", indexpagedata$period[1], ".csv"))
  
}

# scrape_indexpage(XXV)
# scrape_indexpage(XXIV)
# scrape_indexpage(XXIII)
# scrape_indexpage(XXII)
# scrape_indexpage(XXI)
# scrape_indexpage(XX)

```

# merging indexdata dataframes for all legislative periods

```{r}

df_XXV <- read.csv(file = "data/df_XXV.csv", header = TRUE)
df_XXIV <- read.csv(file = "data/df_XXIV.csv", header = TRUE)
df_XXIII <- read.csv(file = "data/df_XXIII.csv", header = TRUE)
df_XXII <- read.csv(file = "data/df_XXII.csv", header = TRUE)
df_XXI <- read.csv(file = "data/df_XXI.csv", header = TRUE)
df_XX <- read.csv(file = "data/df_XX.csv", header = TRUE)

all_indexpagedata <- rbind(df_XXV, df_XXIV, df_XXIII, df_XXII, df_XXI, df_XX)[, -1]

write.csv(all_indexpagedata, file = "data/indexpagedata.csv")

```
# Main

## Scraping from proposal pages

```{r}
indexpagedata <- as_tibble(read.csv(file = "data/indexpagedata.csv", header = TRUE))

# download page for every proposal
proposalpage <- vector(mode = "list", length = length(indexpagedata$proposal_link))

for (i in 4203:length(indexpagedata$proposal_link)) {
  proposalpage[[i]] <- read_html(indexpagedata$proposal_link[i])
  t <- runif(1, 1, 1.2)
  Sys.sleep(t)
  cat(paste0(i, " - waited for ", round(t, 2), " s. "))
}



 scrape_proposal <- function(url) { # url = proposal_link
  
  # scrape bill link (first link in status box)
  bill_link <- proposalpage %>% # div.floatLeft p scrape
    html_node(., "div.floatLeft p a") %>%
    html_attr(., "href") %>%
    paste0("https://www.parlament.gv.at", .)
    
  # scrape resolution Bundesrat (unanonimous, anonimous)
  resolution_BR <- proposalpage %>%
    html_node(., "div.floatLeft p") %>%
    html_text(.) %>%
    str_to_lower(.) %>%
    str_extract(., "bnr\\w+b") %>%
    str_sub(., start = 4L, end  = -2L)
  
  # resolution of Nationalrat (pro, contra) in tibble
  pro <- test %>%
    html_node(., "div.floatLeft p") %>%
    html_text(.) %>%
    str_to_lower(.) %>%
    str_extract(., "daf.+d") %>%
    gsub("[^A-Za-z0-9]", "" , .) %>%
    str_sub(., start = 5L, end = -2L) %>%
    str_split(., "")

  contra <- test %>%
    html_node(., "div.floatLeft p") %>%
    html_text(.) %>%
    str_to_lower(.) %>%
    str_extract(., "dag.+") %>%
    gsub("[^A-Za-z0-9]", "" , .) %>%
    str_sub(., start = 8L, end = -1L) %>%
    str_split(., "")

    # join objects and write list-column (resolution_NR)
    resolution_NR <- list(party = c(pro[[1]], contra[[1]]),
                          pro = c(rep(1, lengths(pro)), rep(0, lengths(contra)))
    )
  
}



```

## Scraping from bill pages

```{r}

#scrape_bill

# download 
html_nodes(billpage, "ul.fliesstext a")[2] %>%
  html_attr("href")

```